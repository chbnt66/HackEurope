# GEO Auditor ğŸ”

**Built at HackEurope â€” Paris, France â€” 21â€“22 February 2026**

GEO Auditor is a full-stack AI-powered tool that analyzes any website's **Generative Engine Optimization (GEO)** score â€” i.e., how likely it is to be cited, summarized, or recommended by AI search tools like ChatGPT, Claude, Gemini, or Perplexity.

---

## ğŸš€ Features

- **Website Crawler** â€” Extracts clean Markdown content and structured JSON-LD data using [Crawl4AI](https://github.com/unclecode/crawl4ai) and BeautifulSoup
- **GEO Audit** â€” Analyzes content with Gemini 2.5 Flash via LangChain and produces:
  - A GEO score (0â€“100)
  - Critical analysis of the site
  - 5 priority recommendations
  - Coherence & comparison score interpretations
- **Coherence Score** â€” Cosine similarity between the site content and its web reputation (via Tavily + Sentence Transformers)
- **Comparison Score** â€” Cosine similarity between the site and the sector leader identified by Tavily
- **`llms.txt` Generation** â€” Auto-generates a compressed Markdown summary optimized for AI crawlers, using [Compresr](https://compresr.com)
- **SEO/AEO Optimizer** â€” Uses Claude (Anthropic) to rewrite content, structured data, and metadata for maximum AI visibility
- **Miro Mind Map Export** â€” Exports the full audit as a visual mind map on a Miro board (via REST API and MCP server)
- **Supabase Webhook Integration** â€” Supports async audit triggering via Supabase Database Webhooks
- **Streamlit Frontend** â€” Interactive web UI for running audits and visualizing results
- **Lovable Frontend** â€” Production-ready React frontend connected to the FastAPI backend

---

## ğŸ“ Project Structure

```
HackEurope/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py                  # FastAPI app â€” /audit, /audit/webhook, /miro/export
â”‚   â”œâ”€â”€ improve_website.py      # Claude-powered SEO/AEO optimizer
â”‚   â”œâ”€â”€ miro_mcp_server.py      # MCP server for Miro mind map export
â”‚   â””â”€â”€ Projet/
â”‚       â”œâ”€â”€ audit_engine.py     # Core GEO audit logic (Gemini + Tavily + Compresr)
â”‚       â”œâ”€â”€ Crawler.py          # Website crawler (Crawl4AI + BeautifulSoup)
â”‚       â””â”€â”€ test.py             # Standalone pipeline test script
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                  # Streamlit UI
â”‚   â””â”€â”€ miro_export.py          # Synchronous Miro export helper
â”œâ”€â”€ environment.yml             # Conda environment definition
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### 1. Clone the repository

```bash
git clone https://github.com/your-org/HackEurope.git
cd HackEurope
```

### 2. Create the Conda environment

```bash
conda env create -f environment.yml
conda activate geo_optimizer_hackathon
```

### 3. Install Playwright browsers (required by Crawl4AI)

```bash
playwright install
```

### 4. Configure environment variables

Create a `.env` file in `backend/Projet/`:

```env
# Google Gemini
GOOGLE_API_KEY=your_google_api_key

# Tavily (web search)
TAVILY_API_KEY=your_tavily_api_key

# Compresr (llms.txt compression)
COMPRESR_API_KEY=your_compresr_api_key

# Anthropic Claude (SEO optimizer)
CLAUDE_API=your_anthropic_api_key

# Miro (mind map export)
MIRO_ACCESS_TOKEN=your_miro_access_token

# Supabase (optional â€” for webhook integration)
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_KEY=your_supabase_service_key
```

---

## â–¶ï¸ Running the Application

### Start the FastAPI backend

```bash
cd backend
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

API available at: `http://localhost:8000`
Interactive docs: `http://localhost:8000/docs`

### Start the Streamlit frontend

```bash
cd frontend
streamlit run app.py
```

### Run the standalone test pipeline

```bash
cd backend/Projet
python test.py
```

### Expose the API publicly (for Supabase webhooks or Lovable frontend)

```bash
ngrok http 8000
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | Health check |
| `POST` | `/audit` | Run a full GEO audit on a URL |
| `POST` | `/audit/webhook` | Supabase webhook trigger |
| `POST` | `/miro/export` | Export audit results to a Miro board |

### Example request

```bash
curl -X POST http://localhost:8000/audit \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

### Example response

```json
{
  "url": "https://example.com",
  "title": "Example Company",
  "markdown_length": 4521,
  "json_ld_count": 2,
  "coherence_score": 0.7843,
  "comparison_score": 0.6120,
  "best_competitor": "Industry Leader Inc.",
  "llms_txt_compressed": "# Example Company\n...",
  "llm_report": "{\"score\": 68, \"critical_analysis\": \"...\", \"top5_recommendations\": [...]}"
}
```

---

## ğŸ§  How It Works

```
URL Input
  â†“
Crawl4AI â†’ Markdown + JSON-LD extraction
  â†“
Tavily â†’ External web reputation search
  â†“
Sentence Transformers â†’ Coherence score (site vs. web)
Sentence Transformers â†’ Comparison score (site vs. sector leader)
  â†“
Gemini 2.5 Flash (LangChain) â†’ GEO audit report
  â†“
Compresr â†’ Compressed llms.txt
  â†“
FastAPI response â†’ Streamlit / Lovable / Supabase
```

---

## ğŸ“š Tech Stack

| Layer | Technology |
|-------|------------|
| LLM (audit) | Google Gemini 2.5 Flash via LangChain |
| LLM (SEO optimizer) | Anthropic Claude Opus |
| Web search | Tavily |
| Embeddings | Sentence Transformers (`all-MiniLM-L6-v2`) |
| Crawler | Crawl4AI + BeautifulSoup |
| Compression | Compresr |
| Backend | FastAPI + Uvicorn |
| Database | Supabase (PostgreSQL) |
| Frontend (demo) | Streamlit |
| Frontend (prod) | Lovable (React) |
| Mind maps | Miro REST API + MCP Server |
| Tunneling | ngrok |

---

## ğŸ“ License

Built during HackEurope 2026. All rights reserved.
